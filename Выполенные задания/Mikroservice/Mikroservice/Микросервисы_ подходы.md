## Задача 1: Обеспечить разработку

Для обеспечения процесса разработки, хранения исходного кода, непрерывной интеграции и непрерывной поставки, я рекомендую использовать следующее решение:

Облачная система: Для достижения гибкости, масштабируемости и доступности я предлагаю использовать платформу Amazon Web Services (AWS) или Microsoft Azure. Оба облачных провайдера предоставляют широкий набор инструментов и служб для разработки, развертывания и управления приложениями.

Система контроля версий Git: Git является широко используемой и надежной системой контроля версий, которая обеспечивает удобное отслеживание изменений в коде, ветвление и слияние веток. Вы можете использовать платформу GitHub или GitLab, которые предоставляют облачные репозитории и инструменты для сотрудничества над проектами.

Непрерывная интеграция и поставка (CI/CD): Для автоматизации сборки, тестирования и развертывания приложений рекомендуется использовать инструменты, такие как Jenkins, Travis CI или CircleCI. Они обеспечивают гибкую настройку пайплайнов CI/CD, интеграцию с системой контроля версий Git и возможность запуска сборки как по событию из системы контроля версий, так и вручную с указанием параметров.

Репозиторий на каждый сервис: Для организации кода каждого сервиса рекомендуется иметь отдельный репозиторий. Это позволяет управлять изменениями в коде отдельно для каждого сервиса, обеспечивает независимость и удобство разработки.

Возможность привязать настройки к каждой сборке: Вы можете использовать конфигурационные файлы или переменные среды, которые могут быть связаны с каждой сборкой. Это позволит устанавливать настройки, такие как секретные данные, параметры сборки и тестирования для каждой сборки независимо.

Создание шаблонов для различных конфигураций сборок: Использование шаблонов позволит снизить дублирование кода и обеспечить единообразие в настройках сборок. Вы можете создать шаблоны с заданными этапами сборки, тестирования и развертывания, которые могут быть переиспользованы для различных проектов или конфигураций.

Безопасное хранение секретных данных: Для хранения и безопасного управления секретными данными, такими как пароли и ключи доступа, рекомендуется использовать инструменты управления секретами, например, AWS Secrets Manager или Vault от HashiCorp. Они позволяют шифровать и централизованно хранить секреты, а также предоставляют API для безопасного доступа к ним во время сборки и развертывания.

Кастомные шаги при сборке: Инструменты непрерывной интеграции, такие как Jenkins или GitLab CI, позволяют определить кастомные шаги сборки, которые могут выполнять специфичные для проекта действия, такие как установка зависимостей, компиляция кода или создание докер-образов.

Собственные докер-образы для сборки проектов: Контейнеризация с помощью Docker обеспечивает независимость от окружения и повторяемость сборок. Вы можете создать собственные докер-образы, содержащие необходимые зависимости и инструменты для сборки проектов, и использовать их в пайплайнах CI/CD.

Развертывание агентов сборки на собственных серверах: Если требуется большая гибкость и контроль над инфраструктурой, вы можете развернуть агенты сборки на собственных серверах или виртуальных машинах. Например, Jenkins предоставляет возможность развертывания агентов на удаленных машинах и запуска сборок на них.

Параллельный запуск нескольких сборок и тестов: Хорошие инструменты непрерывной интеграции позволяют запускать сборки и тесты параллельно для ускорения процесса. Например, можно настроить параллельное выполнение тестов на разных окружениях или различных конфигурациях, чтобы ускорить время выполнения тестовых наборов.

Все вышеупомянутые решения и инструменты обеспечивают широкие возможности для эффективного управления процессом разработки, хранения кода и автоматизации CI/CD. Они также являются популярными и широко поддерживаемыми в сообществе разработчиков, что обеспечивает доступность документации, ресурсов и поддержки.

## Задача 2: Логи


Для обеспечения сбора и анализа логов в микросервисной архитектуре можно использовать ELK-стек (Elasticsearch, Logstash и Kibana), который обладает всеми необходимыми функциями и инструментами.

Logstash: Logstash может использоваться для сбора логов со всех хостов, обслуживающих систему. Он предоставляет гибкий механизм, который позволяет принимать логи из различных источников, например, из stdout приложений, и отправлять их в центральное хранилище.

Elasticsearch: Elasticsearch используется в качестве центрального хранилища для логов. Он обладает распределенной архитектурой, обеспечивая масштабируемость, и позволяет сохранять большие объемы данных. Elasticsearch также предоставляет мощные возможности поиска и фильтрации данных.

Kibana: Kibana работает как пользовательский интерфейс для анализа и визуализации данных из Elasticsearch. Он предоставляет гибкие инструменты для поиска, фильтрации и анализа логов. Разработчики могут получить доступ к Kibana для поиска по записям логов и создания собственных запросов.
Для гарантированной доставки логов можно использовать дополнительные компоненты, такие как Beats или решение, основанное на RabbitMQ или Apache Kafka. Beats позволяют собирать данные и передавать их в Logstash для дальнейшей обработки и индексации в Elasticsearch.

Чтобы предоставить возможность дать ссылку на сохранённый поиск по записям логов, можно использовать функциональность сохранения и совместного использования в Kibana. Пользователь может сохранить свой поиск как сохраненный поиск и поделиться ссылкой на него с другими разработчиками.

 ELK-стек (Elasticsearch, Logstash и Kibana) обеспечивает полный цикл сбора, хранения, анализа и визуализации логов в микросервисной архитектуре. Сочетание этих инструментов позволяет эффективно справляться с обработкой больших объемов данных, обеспечивает удобный поиск и фильтрацию логов, а также предоставляет гибкий пользовательский интерфейс для анализа данных.
 
 ## Задача 3: Мониторинг
 
 
 Для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре можно использовать комбинацию Prometheus, Grafana и Node Exporter.

Prometheus: Prometheus используется для сбора метрик со всех хостов и сервисов. Он предоставляет гибкую модель для определения и сбора метрик, а также поддерживает множество экспортеров, которые могут собирать метрики для различных систем и приложений. В случае микросервисной архитектуры, каждый сервис может экспортировать свой собственный Prometheus экспортер, который будет собирать специфичные метрики для сервиса.

Node Exporter: Node Exporter используется для сбора метрик состояния ресурсов хостов, таких как CPU, RAM, HDD и Network. Он предоставляет предопределенные метрики, которые рассчитываются и экспортируются для каждого хоста.

Grafana: Grafana служит в качестве пользовательского интерфейса для визуализации и анализа собранных метрик. Он обладает широким спектром возможностей по настройке и агрегированию информации, построению графиков, созданию пользовательских панелей и дашбордов. В Grafana можно настроить различные панели для отслеживания состояния системы и настроить запросы для получения интересующей информации.

 Комбинация Prometheus, Grafana и Node Exporter обеспечивает мощный инструментарий для сбора и анализа метрик в микросервисной архитектуре. Prometheus собирает метрики со всех хостов и сервисов, включая специфичные метрики для каждого сервиса. Node Exporter собирает метрики состояния ресурсов хостов. Grafana предоставляет гибкий пользовательский интерфейс для визуализации метрик, настройки запросов и создания панелей для отслеживания состояния системы.
